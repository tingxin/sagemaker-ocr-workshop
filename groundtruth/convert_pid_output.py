"""
ä¸“é—¨è½¬æ¢ä½ çš„ P&ID æ ‡æ³¨è¾“å‡º
æ ¹æ®å®é™…çš„ manifest æ ¼å¼è¿›è¡Œè½¬æ¢
"""

import json
import os
from pathlib import Path
from typing import List, Dict
import random


def convert_pid_manifest_to_training_format(manifest_path: str, output_dir: str):
    """è½¬æ¢ P&ID manifest ä¸ºè®­ç»ƒæ ¼å¼"""
    
    print("=" * 60)
    print("è½¬æ¢ P&ID æ ‡æ³¨æ•°æ®ä¸ºè®­ç»ƒæ ¼å¼")
    print("=" * 60)
    
    # è¯»å– manifest æ–‡ä»¶
    with open(manifest_path, 'r', encoding='utf-8') as f:
        manifest_data = [json.loads(line) for line in f if line.strip()]
    
    print(f"è¯»å–åˆ° {len(manifest_data)} æ¡æ ‡æ³¨è®°å½•")
    
    # åˆ†æç±»åˆ«æ˜ å°„
    all_class_maps = {}
    for item in manifest_data:
        metadata = item.get('pid-label-job-metadata', {})
        class_map = metadata.get('class-map', {})
        all_class_maps.update(class_map)
    
    print(f"ç±»åˆ«æ˜ å°„: {all_class_maps}")
    
    # è½¬æ¢æ•°æ®
    detection_data = []
    
    for item in manifest_data:
        source_ref = item.get('source-ref', '')
        image_name = source_ref.split('/')[-1]
        
        # è·å–æ ‡æ³¨æ•°æ®
        annotation_data = item.get('pid-label-job', {})
        annotations = annotation_data.get('annotations', [])
        image_size = annotation_data.get('image_size', [{}])[0]
        
        img_width = image_size.get('width', 7168)
        img_height = image_size.get('height', 4562)
        
        # è·å–ç±»åˆ«æ˜ å°„
        metadata = item.get('pid-label-job-metadata', {})
        class_map = metadata.get('class-map', all_class_maps)
        
        # è½¬æ¢æ¯ä¸ªæ ‡æ³¨
        detections = []
        for ann in annotations:
            class_id = ann.get('class_id')
            left = ann.get('left', 0)
            top = ann.get('top', 0)
            width = ann.get('width', 0)
            height = ann.get('height', 0)
            
            # è·å–ç±»åˆ«åç§°
            class_name = class_map.get(str(class_id), f"class_{class_id}")
            
            # è½¬æ¢ä¸ºå››ç‚¹åæ ‡ (PaddleOCR æ ¼å¼)
            x1, y1 = int(left), int(top)
            x2, y2 = int(left + width), int(top)
            x3, y3 = int(left + width), int(top + height)
            x4, y4 = int(left), int(top + height)
            
            detections.append({
                "transcription": class_name,
                "points": [[x1, y1], [x2, y2], [x3, y3], [x4, y4]],
                "class": class_name,
                "class_id": class_id,
                "bbox": [left, top, width, height]
            })
        
        if detections:
            detection_data.append({
                "image": image_name,
                "width": img_width,
                "height": img_height,
                "detections": detections
            })
    
    print(f"è½¬æ¢å®Œæˆ: {len(detection_data)} å¼ å›¾ç‰‡")
    
    # ä¿å­˜è½¬æ¢åçš„æ•°æ®
    save_training_formats(detection_data, output_dir, all_class_maps)
    
    return detection_data


def save_training_formats(detection_data: List[Dict], output_dir: str, class_map: Dict):
    """ä¿å­˜å¤šç§è®­ç»ƒæ ¼å¼"""
    
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # éšæœºæ‰“ä¹±æ•°æ®
    random.seed(42)
    random.shuffle(detection_data)
    
    # åˆ’åˆ†æ•°æ®é›†
    total = len(detection_data)
    train_end = int(total * 0.8)
    val_end = train_end + int(total * 0.1)
    
    splits = {
        'train': detection_data[:train_end],
        'val': detection_data[train_end:val_end],
        'test': detection_data[val_end:]
    }
    
    print(f"\næ•°æ®é›†åˆ’åˆ†:")
    for split_name, split_data in splits.items():
        print(f"  {split_name}: {len(split_data)} å¼ å›¾ç‰‡")
    
    # 1. ä¿å­˜ PaddleOCR æ ¼å¼
    paddleocr_dir = output_dir / "paddleocr_format"
    paddleocr_dir.mkdir(exist_ok=True)
    
    for split_name, split_data in splits.items():
        paddleocr_lines = []
        
        for item in split_data:
            image_name = item['image']
            
            # PaddleOCR æ ‡æ³¨æ ¼å¼
            ocr_anns = []
            for det in item['detections']:
                ocr_anns.append({
                    "transcription": det['transcription'],
                    "points": det['points']
                })
            
            if ocr_anns:
                line = f"{image_name}\t{json.dumps(ocr_anns, ensure_ascii=False)}"
                paddleocr_lines.append(line)
        
        # ä¿å­˜ PaddleOCR æ ¼å¼æ–‡ä»¶
        paddleocr_file = paddleocr_dir / f"label_{split_name}.txt"
        with open(paddleocr_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(paddleocr_lines))
        
        print(f"  PaddleOCR {split_name}: {len(paddleocr_lines)} æ¡ -> {paddleocr_file}")
    
    # 2. ä¿å­˜ YOLO æ ¼å¼
    yolo_dir = output_dir / "yolo_format"
    yolo_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºç±»åˆ«åç§°åˆ—è¡¨
    unique_classes = set()
    for item in detection_data:
        for det in item['detections']:
            unique_classes.add(det['class'])
    
    class_names = sorted(list(unique_classes))
    class_to_id = {name: i for i, name in enumerate(class_names)}
    
    # ä¿å­˜ YOLO æ•°æ®é…ç½®
    yolo_config = {
        'path': str(yolo_dir.absolute()),
        'train': 'train',
        'val': 'val',
        'test': 'test',
        'nc': len(class_names),
        'names': class_names
    }
    
    with open(yolo_dir / 'data.yaml', 'w', encoding='utf-8') as f:
        import yaml
        yaml.dump(yolo_config, f, allow_unicode=True)
    
    for split_name, split_data in splits.items():
        split_dir = yolo_dir / split_name
        split_dir.mkdir(exist_ok=True)
        
        for item in split_data:
            image_name = item['image']
            img_width = item['width']
            img_height = item['height']
            
            # YOLO æ ‡æ³¨æ ¼å¼
            yolo_lines = []
            for det in item['detections']:
                bbox = det['bbox']
                class_id = class_to_id[det['class']]
                
                # è½¬æ¢ä¸º YOLO æ ¼å¼ (å½’ä¸€åŒ–)
                x_center = (bbox[0] + bbox[2]/2) / img_width
                y_center = (bbox[1] + bbox[3]/2) / img_height
                norm_width = bbox[2] / img_width
                norm_height = bbox[3] / img_height
                
                yolo_lines.append(f"{class_id} {x_center} {y_center} {norm_width} {norm_height}")
            
            # ä¿å­˜ YOLO æ ‡æ³¨æ–‡ä»¶
            if yolo_lines:
                label_file = split_dir / f"{Path(image_name).stem}.txt"
                with open(label_file, 'w') as f:
                    f.write('\n'.join(yolo_lines))
    
    print(f"  YOLO æ ¼å¼å·²ä¿å­˜åˆ°: {yolo_dir}")
    
    # 3. ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
    generate_statistics(detection_data, output_dir, class_map)


def generate_statistics(detection_data: List[Dict], output_dir: Path, class_map: Dict):
    """ç”Ÿæˆæ•°æ®ç»Ÿè®¡"""
    
    class_counts = {}
    total_detections = 0
    
    for item in detection_data:
        for det in item['detections']:
            class_name = det['class']
            class_counts[class_name] = class_counts.get(class_name, 0) + 1
            total_detections += 1
    
    stats = {
        "total_images": len(detection_data),
        "total_detections": total_detections,
        "avg_detections_per_image": total_detections / len(detection_data),
        "class_mapping": class_map,
        "class_distribution": class_counts
    }
    
    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats_file = output_dir / "statistics.json"
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"  æ€»å›¾ç‰‡æ•°: {stats['total_images']}")
    print(f"  æ€»æ£€æµ‹æ•°: {stats['total_detections']}")
    print(f"  å¹³å‡æ¯å›¾: {stats['avg_detections_per_image']:.1f}")
    print(f"\nç±»åˆ«åˆ†å¸ƒ:")
    for class_name, count in sorted(class_counts.items(), key=lambda x: -x[1]):
        print(f"  {class_name}: {count}")
    
    print(f"\nç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_file}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='è½¬æ¢ P&ID æ ‡æ³¨è¾“å‡º')
    parser.add_argument('--manifest', required=True, help='manifest æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output-dir', default='./pid_training_data', help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.manifest):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.manifest}")
        return
    
    # è½¬æ¢æ•°æ®
    detection_data = convert_pid_manifest_to_training_format(args.manifest, args.output_dir)
    
    print("\n" + "=" * 60)
    print("âœ… è½¬æ¢å®Œæˆ!")
    print("=" * 60)
    print(f"\nè¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"  ğŸ“ paddleocr_format/")
    print(f"     â”œâ”€â”€ label_train.txt")
    print(f"     â”œâ”€â”€ label_val.txt")
    print(f"     â””â”€â”€ label_test.txt")
    print(f"  ğŸ“ yolo_format/")
    print(f"     â”œâ”€â”€ data.yaml")
    print(f"     â”œâ”€â”€ train/ (æ ‡æ³¨æ–‡ä»¶)")
    print(f"     â”œâ”€â”€ val/ (æ ‡æ³¨æ–‡ä»¶)")
    print(f"     â””â”€â”€ test/ (æ ‡æ³¨æ–‡ä»¶)")
    print(f"  ğŸ“„ statistics.json")
    
    print(f"\nğŸš€ ä¸‹ä¸€æ­¥:")
    print(f"  1. è®­ç»ƒæ£€æµ‹æ¨¡å‹:")
    print(f"     python training/train_detection_model.py --data {args.output_dir}/yolo_format/data.yaml")
    print(f"  2. æˆ–ä½¿ç”¨ PaddleOCR æ ¼å¼è¿›è¡Œå…¶ä»–è®­ç»ƒ")


if __name__ == '__main__':
    main()